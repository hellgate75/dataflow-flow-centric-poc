Welcome in Flow Centric PoC
---------------------------
---------------------------



Goals
-----
Goal of this Poc is to demonstrate how to parse and store locally uncertain and complex JSON files from one source.
As model we took as inmput we run a data generator that streams over a Kafka local server.
Data is captured by a Sping DataFlow streaming workflow that from the source service send data to processor that give a shape to that data, then to a sink service that save that data on a local MongoDb. Data flow will be marked on a local
instance of H2 database with a predefined schema.


As first: 

Preconditions:
--------------
Please check following preconditions:

* git bash is a must to run the script

* in the system you need have installed :
      * JDK 1.8.xxx (reccomended: 1.8.0_241) as primary java command
      * CYGWIN (32-bit or 64-bit [preferred])
      * Possibly run on 64-bit environment (due to OS choice)

* internet connection is necessary

* prevent to bypass proxy servers can block some internet connectors (wget, url, git pull)



Installation of the Poc services:
---------------------------------
On the git shell into the script folder please run following script:
* install-start-services.sh

Take note that installation as start-up or stop of services cannot be manual. In that case
you have to befine as first an environemnt variable as follow:

export BASE_DIR=\"<full-path-to-script-folder>\"

You can determine that value running:

echo "$(pwd)"


On first run to complete DataFlow server configuration we start up all services



Start of Services Post-Installation
-----------------------------------

On the git shell into the script folder please run following script:
* start-services.sh



Stop of Services Post-Installation
----------------------------------

On the git shell into the script folder please run following script:
* stop-services.sh



Bill of materials
-----------------

Following services will be installed:
* local Apache Kafka
* local H2 database
* local MongoDb
* local Spring Cloud Config Server (part of infrastructure of the PoC, and containing services configuration)
* local Spring Cloud DataFlow Server and Shell
* local Spring Cloud Skipper Server / Shell (as support of the Spring Cloud DataFlow Server)
* services : Source, Process, Sink
* actuators: Random Data Generator and Pumper (pumps data into Apache Kafka in order to start new stream processing)


NOTES:

This PoC doesn't work on Linux. We applied patch to run it in a specific environemnt (Windows, in git shell with the presence of CygWin)

Zookerper Admin Url : http://localhost:9188/commands
